{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fffb1c3690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1) # 랜덤시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.], requires_grad=True), tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True) # 가중치 W를 0으로 초기화\n",
    "b = torch.zeros(1, requires_grad=True) # required_grad는 학습을 통해 값을 변경\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 10  W : tensor([0.1867], requires_grad=True), b : tensor([0.0800], requires_grad=True), C : 18.66666603088379\n",
      "1 / 10  W : tensor([0.3527], requires_grad=True), b : tensor([0.1509], requires_grad=True), C : 14.770962715148926\n",
      "2 / 10  W : tensor([0.5004], requires_grad=True), b : tensor([0.2138], requires_grad=True), C : 11.691540718078613\n",
      "3 / 10  W : tensor([0.6318], requires_grad=True), b : tensor([0.2695], requires_grad=True), C : 9.257344245910645\n",
      "4 / 10  W : tensor([0.7487], requires_grad=True), b : tensor([0.3188], requires_grad=True), C : 7.333169460296631\n",
      "5 / 10  W : tensor([0.8528], requires_grad=True), b : tensor([0.3625], requires_grad=True), C : 5.812135219573975\n",
      "6 / 10  W : tensor([0.9453], requires_grad=True), b : tensor([0.4012], requires_grad=True), C : 4.6097636222839355\n",
      "7 / 10  W : tensor([1.0277], requires_grad=True), b : tensor([0.4353], requires_grad=True), C : 3.65927791595459\n",
      "8 / 10  W : tensor([1.1011], requires_grad=True), b : tensor([0.4655], requires_grad=True), C : 2.907895803451538\n",
      "9 / 10  W : tensor([1.1663], requires_grad=True), b : tensor([0.4922], requires_grad=True), C : 2.313894510269165\n",
      "10 / 10  W : tensor([1.2245], requires_grad=True), b : tensor([0.5157], requires_grad=True), C : 1.8442937135696411\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    \n",
    "    H = x_train * W + b # 가설 수립\n",
    "    C = torch.mean((H - y_train) ** 2) # 손실함수\n",
    "    \n",
    "    opt = optim.SGD([W, b], lr=0.01) # 최적화함수\n",
    "    opt.zero_grad() # 경사를 0으로 초기화\n",
    "    C.backward() # 손실함수를 미분하여 경사 계산\n",
    "    opt.step() # W, b 업데이트\n",
    "    \n",
    "    print(f'{epoch} / {epochs}  W : {W}, b : {b}, C : {C}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w : 2.0\n",
      "w : 4.0\n",
      "w : 6.0\n",
      "w : 8.0\n",
      "w : 10.0\n",
      "w : 12.0\n",
      "w : 14.0\n",
      "w : 16.0\n",
      "w : 18.0\n",
      "w : 20.0\n",
      "w : 22.0\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True) # 가중치를 초기화하지 않았을 경우\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    z = 2 * w\n",
    "    z.backward()\n",
    "    print(f'w : {w.grad}') # 기울기 값을 누적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자동 미분(Autograd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "y = w ** 2\n",
    "z = 2 * y + 5\n",
    "\n",
    "z.backward() # 수식의 w에 대한 기울기 계산(미분)\n",
    "w.grad # w 미분값 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 0.29401201009750366, 0.2935999929904938, 0.2973800003528595, 0.0034199999645352364, 29661.80078125\n",
      "1/10 0.45864337682724, 0.45794832706451416, 0.46387481689453125, 0.005335401743650436, 9298.5205078125\n",
      "2/10 0.5508393049240112, 0.5499333739280701, 0.5570917725563049, 0.0064084334298968315, 2915.712158203125\n",
      "3/10 0.6024811863899231, 0.6014048457145691, 0.6092831492424011, 0.007009853143244982, 915.0398559570312\n",
      "4/10 0.6314184665679932, 0.6301943063735962, 0.6385058760643005, 0.00734723499044776, 287.9359130859375\n",
      "5/10 0.6476441621780396, 0.6462849378585815, 0.6548691987991333, 0.007536791265010834, 91.37100982666016\n",
      "6/10 0.6567531228065491, 0.6552659869194031, 0.664033055305481, 0.007643585558980703, 29.75813865661621\n",
      "7/10 0.6618777513504028, 0.660266637802124, 0.6691662073135376, 0.007704044692218304, 10.445318222045898\n",
      "8/10 0.6647716164588928, 0.6630387902259827, 0.672042727470398, 0.007738562300801277, 4.391228199005127\n",
      "9/10 0.666416585445404, 0.6645633578300476, 0.6736558079719543, 0.0077585563994944096, 2.493135452270508\n",
      "10/10 0.6673623323440552, 0.6653894186019897, 0.6745615601539612, 0.007770418655127287, 1.8976879119873047\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    \n",
    "    H = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "    C = torch.mean((H - y_train) ** 2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    C.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'{epoch}/{epochs} {w1.item()}, {w2.item()}, {w3.item()}, {b.item()}, {C.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 연산\n",
    "\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100], \n",
    "                               [73,  66,  70]])\n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 H : tensor([0., 0., 0., 0., 0.]), C : 29661.80078125\n",
      "1/10 H : tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]), C : 9537.6943359375\n",
      "2/10 H : tensor([104.5421, 125.6208, 119.2478, 134.7861,  95.8280]), C : 3069.5908203125\n",
      "3/10 H : tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]), C : 990.6702880859375\n",
      "4/10 H : tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]), C : 322.48187255859375\n",
      "5/10 H : tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]), C : 107.7170639038086\n",
      "6/10 H : tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]), C : 38.687496185302734\n",
      "7/10 H : tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]), C : 16.499042510986328\n",
      "8/10 H : tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]), C : 9.365655899047852\n",
      "9/10 H : tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]), C : 7.071113586425781\n",
      "10/10 H : tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]), C : 6.331847190856934\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((3, 1), requires_grad=True) # x_train (5, 3)과 행렬곱\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "opt = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    H = x_train.matmul(W) + b # 행결곱 연산\n",
    "    C = torch.mean((H - y_train) ** 2)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    C.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(f'{epoch}/{epochs} H : {H.squeeze().detach()}, C : {C.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Module로 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.5153]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4414], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "model = nn.Linear(in_features=1, out_features=1) # 입/출력 차원\n",
    "list(model.parameters()) # W, b 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 cost : 13.103541374206543\n",
      "1/10 cost : 10.35857105255127\n",
      "2/10 cost : 8.188817024230957\n",
      "3/10 cost : 6.473737716674805\n",
      "4/10 cost : 5.1180548667907715\n",
      "5/10 cost : 4.046455383300781\n",
      "6/10 cost : 3.1994102001190186\n",
      "7/10 cost : 2.5298609733581543\n",
      "8/10 cost : 2.0006134510040283\n",
      "9/10 cost : 1.5822678804397583\n",
      "10/10 cost : 1.251583218574524\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=0.01) # W, b 전달\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    pred = model(x_train) # H(x) 계산\n",
    "    cost = F.mse_loss(pred, y_train)\n",
    "    \n",
    "    opt.zero_grad() # 경사 0 초기화\n",
    "    cost.backward() # 손실함수 미분\n",
    "    opt.step() # W, b 업데이트\n",
    "    \n",
    "    print(f'{epoch}/{epochs} cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.1553]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[4.0]])\n",
    "pred_y = model(new_var) # forward 연산\n",
    "pred_y # 최적화 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[1.5381]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0030], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1119,  0.2710, -0.5435]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3462], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 선형 회귀 구현\n",
    "\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "model = nn.Linear(3, 1) # 다중선형회귀 입/출력\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 cost : 42134.70703125\n",
      "1/10 cost : 13211.302734375\n",
      "2/10 cost : 4145.35107421875\n",
      "3/10 cost : 1303.652099609375\n",
      "4/10 cost : 412.92913818359375\n",
      "5/10 cost : 133.73214721679688\n",
      "6/10 cost : 46.216514587402344\n",
      "7/10 cost : 18.782730102539062\n",
      "8/10 cost : 10.181428909301758\n",
      "9/10 cost : 7.483162879943848\n",
      "10/10 cost : 6.635087013244629\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5) # 0.00001\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    pred = model(x_train) # H(x) 계산\n",
    "    cost = F.mse_loss(pred, y_train)\n",
    "    \n",
    "    opt.zero_grad() # 경사 0 초기화\n",
    "    cost.backward() # 손실함수 미분\n",
    "    opt.step() # W, b 업데이트\n",
    "    \n",
    "    print(f'{epoch}/{epochs} cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[154.8908]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_var =  torch.FloatTensor([[73, 80, 75]])\n",
    "pred_y = model(new_var)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.6839, 1.0633, 0.2607]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3555], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스로 파이토치 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModel(\n",
       "   (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " [Parameter containing:\n",
       "  tensor([[-0.2057]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.5087], requires_grad=True)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module): # torch.nn.Module을 상속받는 클래스\n",
    "    def __init__(self): # 생성자 정의\n",
    "        super().__init__() # nn.Module의 속성으로 초기화(상속)\n",
    "        self.linear = nn.Linear(1, 1) # 단순선형회귀\n",
    "    \n",
    "    def forward(self, x): # model 객체를 데이터와 호출시 forward 연산\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "model, list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 cost : 18.47460174560547\n",
      "1/10 cost : 14.648292541503906\n",
      "2/10 cost : 11.623584747314453\n",
      "3/10 cost : 9.232498168945312\n",
      "4/10 cost : 7.342257022857666\n",
      "5/10 cost : 5.847909450531006\n",
      "6/10 cost : 4.6664958000183105\n",
      "7/10 cost : 3.732438802719116\n",
      "8/10 cost : 2.9939069747924805\n",
      "9/10 cost : 2.4099276065826416\n",
      "10/10 cost : 1.9481143951416016\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    pred = model(x_train)\n",
    "    cost = F.mse_loss(pred, y_train)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(f'{epoch}/{epochs} cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultivariateRegressionModel(\n",
       "   (linear): Linear(in_features=3, out_features=1, bias=True)\n",
       " ),\n",
       " [Parameter containing:\n",
       "  tensor([[ 0.0803, -0.0707,  0.1601]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.0285], requires_grad=True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultivariateRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중ㅎ선형회구\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = MultivariateRegressionModel()\n",
    "model, list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 cost : 24821.373046875\n",
      "1/10 cost : 7780.78271484375\n",
      "2/10 cost : 2439.46240234375\n",
      "3/10 cost : 765.2409057617188\n",
      "4/10 cost : 240.461669921875\n",
      "5/10 cost : 75.9710693359375\n",
      "6/10 cost : 24.411727905273438\n",
      "7/10 cost : 8.250520706176758\n",
      "8/10 cost : 3.1846110820770264\n",
      "9/10 cost : 1.5965745449066162\n",
      "10/10 cost : 1.0986335277557373\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    pred = model(x_train)\n",
    "    cost = F.mse_loss(pred, y_train)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    cost.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print(f'{epoch}/{epochs} cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니배치와 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mini batch : 전체 데이터를 작은 단위로 나누어서 학습. 미니배치에 대한 손실 계산하여 경사하강.\n",
    "* 미니배치의 개수만큼 경사하강을 수행 = 1 에포크 수행\n",
    "* 미니배치를 적용하면 수렴과정에서 조금 헤매지만, 훈련속도 상승\n",
    "* iteration = data size / batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 batch 1/3, cost : 32868.546875\n",
      "0/10 batch 2/3, cost : 8253.9765625\n",
      "0/10 batch 3/3, cost : 3580.59423828125\n",
      "1/10 batch 1/3, cost : 670.8707885742188\n",
      "1/10 batch 2/3, cost : 462.1192626953125\n",
      "1/10 batch 3/3, cost : 113.4438247680664\n",
      "2/10 batch 1/3, cost : 18.598493576049805\n",
      "2/10 batch 2/3, cost : 9.061540603637695\n",
      "2/10 batch 3/3, cost : 4.041672706604004\n",
      "3/10 batch 1/3, cost : 0.02078815922141075\n",
      "3/10 batch 2/3, cost : 0.833903431892395\n",
      "3/10 batch 3/3, cost : 0.6934444904327393\n",
      "4/10 batch 1/3, cost : 0.16375519335269928\n",
      "4/10 batch 2/3, cost : 0.7541210651397705\n",
      "4/10 batch 3/3, cost : 0.2974722385406494\n",
      "5/10 batch 1/3, cost : 0.3930050730705261\n",
      "5/10 batch 2/3, cost : 0.13499924540519714\n",
      "5/10 batch 3/3, cost : 0.50543212890625\n",
      "6/10 batch 1/3, cost : 0.402871310710907\n",
      "6/10 batch 2/3, cost : 0.22851325571537018\n",
      "6/10 batch 3/3, cost : 0.4023658335208893\n",
      "7/10 batch 1/3, cost : 0.40940040349960327\n",
      "7/10 batch 2/3, cost : 0.23728951811790466\n",
      "7/10 batch 3/3, cost : 0.2137453705072403\n",
      "8/10 batch 1/3, cost : 0.26417121291160583\n",
      "8/10 batch 2/3, cost : 0.21856822073459625\n",
      "8/10 batch 3/3, cost : 0.5234236121177673\n",
      "9/10 batch 1/3, cost : 0.37075644731521606\n",
      "9/10 batch 2/3, cost : 0.2130586951971054\n",
      "9/10 batch 3/3, cost : 0.4663412868976593\n",
      "10/10 batch 1/3, cost : 0.465335875749588\n",
      "10/10 batch 2/3, cost : 0.2389996498823166\n",
      "10/10 batch 3/3, cost : 0.1808481514453888\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "dataset = TensorDataset(x_train, y_train) # 텐서를 입력으로 받음\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) # 배치사이즈는 통상 2의 배수\n",
    "\n",
    "model = nn.Linear(3, 1)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        \n",
    "        x_train, y_train = samples\n",
    "        \n",
    "        pred = model(x_train)\n",
    "        cost = F.mse_loss(pred, y_train)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        cost.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        print(f'{epoch}/{epochs} batch {batch_idx + 1}/{len(dataloader)}, cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151.4803]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "pred_y = model(new_var)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커스텀 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset): # Dataset을 상속하여 커스텀 데이터셋\n",
    "    def __init__(self):\n",
    "        \"\"\"데이터셋 전처리 부분\"\"\"\n",
    "    \n",
    "    def __len__(self): # 데이터셋 샘플수\n",
    "        \"\"\"데이터셋 샘플 수\"\"\"\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"데이터셋에서 특정 샘플을 가져오는 함수\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 batch 1/3, cost : 14629.7578125\n",
      "0/10 batch 2/3, cost : 11342.603515625\n",
      "0/10 batch 3/3, cost : 2022.75390625\n",
      "1/10 batch 1/3, cost : 689.2694091796875\n",
      "1/10 batch 2/3, cost : 134.20736694335938\n",
      "1/10 batch 3/3, cost : 5.936200141906738\n",
      "2/10 batch 1/3, cost : 72.03196716308594\n",
      "2/10 batch 2/3, cost : 1.1696885824203491\n",
      "2/10 batch 3/3, cost : 0.005811456590890884\n",
      "3/10 batch 1/3, cost : 30.07878875732422\n",
      "3/10 batch 2/3, cost : 4.975607872009277\n",
      "3/10 batch 3/3, cost : 5.224031448364258\n",
      "4/10 batch 1/3, cost : 1.1434930562973022\n",
      "4/10 batch 2/3, cost : 17.939682006835938\n",
      "4/10 batch 3/3, cost : 13.93496036529541\n",
      "5/10 batch 1/3, cost : 12.485429763793945\n",
      "5/10 batch 2/3, cost : 6.557172775268555\n",
      "5/10 batch 3/3, cost : 19.813745498657227\n",
      "6/10 batch 1/3, cost : 14.490995407104492\n",
      "6/10 batch 2/3, cost : 10.984434127807617\n",
      "6/10 batch 3/3, cost : 9.938329696655273\n",
      "7/10 batch 1/3, cost : 7.2875542640686035\n",
      "7/10 batch 2/3, cost : 18.251949310302734\n",
      "7/10 batch 3/3, cost : 9.30838394165039\n",
      "8/10 batch 1/3, cost : 0.5572391748428345\n",
      "8/10 batch 2/3, cost : 10.844191551208496\n",
      "8/10 batch 3/3, cost : 25.25225067138672\n",
      "9/10 batch 1/3, cost : 13.566673278808594\n",
      "9/10 batch 2/3, cost : 17.787385940551758\n",
      "9/10 batch 3/3, cost : 7.119604110717773\n",
      "10/10 batch 1/3, cost : 14.568340301513672\n",
      "10/10 batch 2/3, cost : 11.61421012878418\n",
      "10/10 batch 3/3, cost : 7.3657379150390625\n"
     ]
    }
   ],
   "source": [
    "# 선형회귀\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset): # Dataset을 상속하여 커스텀 데이터셋\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                    [93, 88, 93],\n",
    "                    [89, 91, 90],\n",
    "                    [96, 98, 100],\n",
    "                    [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "    \n",
    "    def __len__(self): # 데이터셋 샘플수\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "model = torch.nn.Linear(3, 1)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        x_train, y_train = samples\n",
    "        pred = model(x_train)\n",
    "        cost = F.mse_loss(pred, y_train)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        cost.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        print(f'{epoch}/{epochs} batch {batch_idx + 1}/{len(dataloader)}, cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[162.8903]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[73, 90, 75]])\n",
    "pred_y = model(new_var)\n",
    "pred_y"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76888c4a1af33f53bb52de03cc72a37cdcfc80966b4bb342e552f029c3bcc4e2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
